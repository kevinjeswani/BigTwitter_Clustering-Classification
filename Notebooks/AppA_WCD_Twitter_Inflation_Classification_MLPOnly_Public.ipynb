{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2e8b7c8-1069-4563-a4e3-31d0543f08eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Appendix A) WCD BIG DATA PROJECT - TWITTER SENTIMENT ANALYSIS - INFLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e447e63-2a4c-4a31-87cf-db4602ad15d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Multi-Layer Perceptron (MLP) Classifier (Neural Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49855c94-379d-4be5-95d0-d873d9bbdf19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**WeCloudData Bootcamp 2022 (Part-time Cohort)**<br> </font>\n",
    "By: Kevin Jeswani & Junaid Zafar <br>\n",
    "The set of notebooks are segmented for the purpose of clarity & convenience <br>\n",
    "The following is the suggested order for running the scripts:\n",
    "- '1_WCD_Twitter_Inflation_Classification' - Mounted S3 bucket for inflation tweets, copied over twitter data, tweet cleaning. VADER & Spark-NLP pre-trained model is used to apply labels to the inflation tweets. The data is then transformed with spark-ml. Logistic regression & random forest are built and trained with gridsearchCV on the label and transformed token features.\n",
    "- '2_WCD_Twitter_AllTopics_Clustering'  - All topics in the WCD twitter bucket are filtered, custom transformers are built and inserted into an extensive pipeline to load raw data from Kinesis firehose. Clustering uses Latent Dirichlet Allocation is conducted using a custom gridsearch to perform topic modelling.<br>\n",
    "\n",
    "**Appendices** - Please note these notebooks are included simply as supporting information and to show that other experiments and exercises were conduct. Less time and effort was spent formatting on these notebooks, whereas Notebook 1) and 2) are the main submission documents.\n",
    "- 'AppA_WCD_Twitter_Inflation_Classification_MLPOnly'**This Notebook**  - Experimentation for classification with multi-layer perceptron models - originally at the end of Notebook 1)\n",
    "- 'AppB_WCD_Twitter_Inflation_Clustering' -Inflation tweet data with Spark-NLP labels imported, custom transformer for data cleaning built and combined with standard nlp transformers in a pipeline. LDA clustering implemented to model topics in the inflation dataset. An attemp was made with a GMM clustering model.\n",
    "- 'AppC_WCD_Twitter_AllTopics_52mil_Clustering' - ALL streamed tweets (55mil+) are loaded from the WCD bucket, a transformation pipeline is built and all the data is transformed. A LDM clustering is built to cluster all the topics. \n",
    "- 'AppD_WCD_Twitter_AllTopics_Clustering_Evaluation' - An attempt was made to visualize the clustering using principal component analysis and t-SNE, but the data transformation required was too heavy to process and other issues occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76c0aba2-c392-4177-be33-6dccd9c207e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook is just a collection of what was taken out from Notebook 1: Classification on Inflation Tweets <br>\n",
    "\n",
    "It is not meant to be run as a standalone, but just to serve as proof of advanced experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dba02f17-dbd9-4340-a596-5876243adc0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note:** An attempt was made to use an MLP but after hours of research and debugging, a solution could not be found as the features structure is not consistent for every element. It seems to work with pyspark-ml's other classifers, but not the MLP. The following section would need to be explored further in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09a6b4de-1732-4a90-a3b1-9c13c403ecb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Section Imports\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7404b1bd-4192-41a7-a2ce-19cfefdcd00f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this section, a spark-native MLP classifier (a artificial neural-net) is trained using the processed tweet token 'features' (with all the feature transformer applied from Section 2)\n",
    "- A perceptron is a mathematical representation of a neuron, in which the inputs are combined in a weighted sum. When the weighted sum exceeds a given threshold specified as an activation function, the neuron is engaged and produces an output.\n",
    "- The outputs can be binary, hence used in a binary classifier, which then defines a linear decision boundary. In a hyperplane, the distance between falsely classfied points and the decision boundary is minized using the stochastic gradient descent optimization function.\n",
    "- The rectified Linear Unit (ReLU) is often used as the neuronal activation function\n",
    "- The MLP has multiple input and output layers and 1+ hidden layers with multiple neurons stacked together; inputs are combined with initial weights in a weight sum then the activation function is applied. However the differences between each linear combination is propagated through the succeceeding layer\n",
    "- It uses the backpropagation as the mechanism to combine inputs and weights in a neuron to iteratively adjust weights in the entire network to minimize the cost function <br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*MF1q2Q3fbpYlXX8fZUiwpA.webp\" width = \"400\"/> <br>\n",
    "Source: https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141 <br>\n",
    "**Advantages:**\n",
    "- Applicable to complex non-linear problems\n",
    "- Works well with large input data\n",
    "- Provides quick predictions after training\n",
    "- The same accuracy ratio can be achieved with smaller datasets <br>\n",
    "**Disadvantages:**\n",
    "- Independent variable contributions are unknown (black-box-y)\n",
    "- Computatational expensive\n",
    "- Functionality of model depends on training set quality <br>\n",
    "Source: https://www.researchgate.net/figure/Multilayer-Perceptron-Advantages-and-Disadvantages_tbl4_338950098\n",
    "<br>\n",
    "**Parameters of Interest:**\n",
    "- Layers = vector of neurons in [#input layer,#hidden layer, #hidden layer,#output layer]; output neurons to match number of classes, input layers approximately the number of input features (generally around 12 words in features col, hidden layers chosen arbitrarily) <Br>\n",
    "**More info here:**\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html#pyspark.ml.classification.MultilayerPerceptronClassifier <br>\n",
    "https://medium.com/swlh/pysparks-multi-layer-perceptron-classifier-on-iris-dataset-dcf70d553cd8 <br>\n",
    "https://medium.com/analytics-vidhya/spark-mllibs-multilayer-perceptron-classifier-mlpc-hands-on-32ac4014eee9 <br>\n",
    "https://towardsdatascience.com/spark-multilayer-perceptron-classifier-for-poi-classification-99e5c68b4a77 <br>\n",
    "https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79829d8c-1bdf-4706-b403-08acb5214233",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setup MLP Model & Train\n",
    "mlp_classifier =  MultilayerPerceptronClassifier(layers= [12, 24, 24, 3], seed=123) #Initialize classifier - by default it will try and find 'features' col and 'label' col\n",
    "# 3 outputs neurons (pos,neg,neut)\n",
    "mlp_model = mlp_classifier.fit(trainSet) #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeea61ce-f8ed-48c4-b98d-c38740fe627b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Input data shape: {trainSet.shape}\")\n",
    "print(f\"Model shape: {mlp_model.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f48d566-9a03-4fa0-977d-895c97b88c03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "mlp_model.save(\"~/mlmodels/models/Twitter_MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd4da5f7-f2db-429d-8701-3c8945202c99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "mlp_model_in = MultilayerPerceptronClassificationModel.load(\"dbfs:/~/mlmodels/models/Twitter_MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33f59731-a1c0-4f15-862b-b67f1b2a3111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlp_pred_test = mlp_model_in.transform(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "777278cb-55e4-403b-ace8-43365adae456",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(mlp_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e1bad6c-81f4-46b9-a748-06f7c624f50f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# EXCEPTION WILL OCCUR HERE AS FEATURES CANNOT BE READ FOR TRANSFORMATION FOR SOME REASON\n",
    "trainSet_ = trainSet.select('*',trainSet['features']['values'].alias(\"feat_explode\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1b4c436-325b-40ef-9fbd-fc76c551a6da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(trainSet.select(\"features\").first()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05088f06-bfcf-47b0-82ef-e203e346f46a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(tweets_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2b55ffb-e730-4217-8e56-c226f1de5910",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Try to use other transformers to standardize the number of features - STILL NOT WORKING\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "vecindexer = VectorIndexer(maxCategories=12,inputCol=\"features\",outputCol=\"features_\")\n",
    "vecindexer_model = vecindexer.fit(tweets_features)\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorIndexer.html#pyspark.ml.feature.VectorIndexer\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorSlicer.html#pyspark.ml.feature.VectorSlicer\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorSlicer.html#pyspark.ml.feature.VectorSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9c2cf6-5875-409f-acea-6d951657fe3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tweets_features2 = vecindexer_model.transform(tweets_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1126be69-4c41-4a91-a78e-65851767a234",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Note:** The MLP model being developed in above was facing issues with the size of the input features - ideally one could create a vector size hinter and filter out vectors that do not match the specified vector size. The problem being that it is trying to change the size of total feature among the entire document and not the features selected at the element level. This section is just here as a preview of what else could be explored in the future. <br>\n",
    "See: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorSizeHint.html <br>\n",
    "https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3f85950-30e3-4538-bfd7-80fc20ceaafb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Feature Assembly - With VectorSizeHinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fdba620-e6ad-4c49-b77b-e4c1df11e13c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import VectorSizeHint, VectorAssembler\n",
    "sizehint = VectorSizeHint(inputCol=\"features\",size=10,handleInvalid=\"skip\")\n",
    "tweets_features = sizehint.transform(tweets_features)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4127441877001980,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "AppA_WCD_Twitter_Inflation_Classification_MLPOnly_Public",
   "notebookOrigID": 2850413760327982,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
